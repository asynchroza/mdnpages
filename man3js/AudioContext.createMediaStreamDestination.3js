.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "AudioContext.createMediaStreamDestination" "JS" "November 28, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioContext.createMediaStreamDestination \- AudioContext:
createMediaStreamDestination() method
.SH SYNOPSIS
The \f[CR]createMediaStreamDestination()\f[R] method of the
\f[CR]AudioContext\f[R] Interface is used to create a new
\f[CR]MediaStreamAudioDestinationNode\f[R] object associated with a
WebRTC \f[CR]MediaStream\f[R] representing an audio stream, which may be
stored in a local file or sent to another computer.
.PP
The \f[CR]MediaStream\f[R] is created when the node is created and is
accessible via the \f[CR]MediaStreamAudioDestinationNode\f[R]\[cq]s
\f[CR]stream\f[R] attribute.
This stream can be used in a similar way as a \f[CR]MediaStream\f[R]
obtained via \f[CR]navigator.getUserMedia\f[R] \[em] it can, for
example, be sent to a remote peer using the \f[CR]addStream()\f[R]
method of \f[CR]RTCPeerConnection\f[R].
.PP
For more details about media stream destination nodes, check out the
\f[CR]MediaStreamAudioDestinationNode\f[R] reference page.
.SH SYNTAX
.IP
.EX
createMediaStreamDestination()
.EE
.SS Parameters
None.
.SS Return value
A \f[CR]MediaStreamAudioDestinationNode\f[R].
.SH EXAMPLES
In the following simple example, we create a
\f[CR]MediaStreamAudioDestinationNode\f[R], an \f[CR]OscillatorNode\f[R]
and a \f[CR]MediaRecorder\f[R] (the example will therefore only work in
Firefox and Chrome at this time.)
The \f[CR]MediaRecorder\f[R] is set up to record information from the
\f[CR]MediaStreamDestinationNode\f[R].
.PP
When the button is clicked, the oscillator starts, and the
\f[CR]MediaRecorder\f[R] is started.
When the button is stopped, the oscillator and \f[CR]MediaRecorder\f[R]
both stop.
Stopping the \f[CR]MediaRecorder\f[R] causes the
\f[CR]dataavailable\f[R] event to fire, and the event data is pushed
into the \f[CR]chunks\f[R] array.
After that, the \f[CR]stop\f[R] event fires, a new \f[CR]blob\f[R] is
made of type opus \[em] which contains the data in the \f[CR]chunks\f[R]
array, and a new window (tab) is then opened that points to a URL
created from the blob.
.PP
From here, you can play and save the opus file.
.IP
.EX
<!doctype html>
<html lang=\[dq]en\-US\[dq]>
  <head>
    <meta charset=\[dq]UTF\-8\[dq] />
    <title>createMediaStreamDestination() demo</title>
  </head>
  <body>
    <h1>createMediaStreamDestination() demo</h1>

    <p>Encoding a pure sine wave to an Opus file</p>
    <button>Make sine wave</button>
    <audio controls></audio>
    <script>
      const b = document.querySelector(\[dq]button\[dq]);
      let clicked = false;
      const chunks = [];
      const ac = new AudioContext();
      const osc = ac.createOscillator();
      const dest = ac.createMediaStreamDestination();
      const mediaRecorder = new MediaRecorder(dest.stream);
      osc.connect(dest);

      b.addEventListener(\[dq]click\[dq], (e) => {
        if (!clicked) {
          mediaRecorder.start();
          osc.start(0);
          e.target.textContent = \[dq]Stop recording\[dq];
          clicked = true;
        } else {
          mediaRecorder.stop();
          osc.stop(0);
          e.target.disabled = true;
        }
      });

      mediaRecorder.ondataavailable = (evt) => {
        // Push each chunk (blobs) in an array
        chunks.push(evt.data);
      };

      mediaRecorder.onstop = (evt) => {
        // Make blob out of our blobs, and open it.
        const blob = new Blob(chunks, { type: \[dq]audio/ogg; codecs=opus\[dq] });
        document.querySelector(\[dq]audio\[dq]).src = URL.createObjectURL(blob);
      };
    </script>
  </body>
</html>
.EE
.RS
.PP
\f[B]Note:\f[R] You can \c
.UR
https://mdn.github.io/webaudio-examples/create-media-stream-destination/index.html
view this example live
.UE \c
, or \c
.UR
https://github.com/mdn/webaudio-examples/blob/main/create-media-stream-destination/index.html
study the source code
.UE \c
, on GitHub.
.RE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API
