.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "AudioBuffer" "JS" "July 7, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioBuffer \- AudioBuffer
.SH SYNOPSIS
The \f[B]\f[CB]AudioBuffer\f[B]\f[R] interface represents a short audio
asset residing in memory, created from an audio file using the
\f[CR]AudioContext.decodeAudioData()\f[R] method, or from raw data using
\f[CR]AudioContext.createBuffer()\f[R].
Once put into an AudioBuffer, the audio can then be played by being
passed into an \f[CR]AudioBufferSourceNode\f[R].
.PP
Objects of these types are designed to hold small audio snippets,
typically less than 45 s.
For longer sounds, objects implementing the
\f[CR]MediaElementAudioSourceNode\f[R] are more suitable.
The buffer contains the audio signal waveform encoded as a series of
amplitudes in the following format: non\-interleaved IEEE754 32\-bit
linear PCM with a nominal range between \f[CR]\-1\f[R] and
\f[CR]+1\f[R], that is, a 32\-bit floating point buffer, with each
sample between \-1.0 and 1.0.
If the \f[CR]AudioBuffer\f[R] has multiple channels, they are stored in
separate buffers.
.SH CONSTRUCTOR
.TP
\f[B]AudioBuffer()\f[R]
Creates and returns a new \f[CR]AudioBuffer\f[R] object instance.
.SH INSTANCE PROPERTIES
.TP
\f[B]AudioBuffer.sampleRate\f[R] \f[I](read\-only)\f[R]
Returns a float representing the sample rate, in samples per second, of
the PCM data stored in the buffer.
.TP
\f[B]AudioBuffer.length\f[R] \f[I](read\-only)\f[R]
Returns an integer representing the length, in sample\-frames, of the
PCM data stored in the buffer.
.TP
\f[B]AudioBuffer.duration\f[R] \f[I](read\-only)\f[R]
Returns a double representing the duration, in seconds, of the PCM data
stored in the buffer.
.TP
\f[B]AudioBuffer.numberOfChannels\f[R] \f[I](read\-only)\f[R]
Returns an integer representing the number of discrete audio channels
described by the PCM data stored in the buffer.
.SH INSTANCE METHODS
.TP
\f[B]AudioBuffer.getChannelData()\f[R]
Returns a \f[CR]Float32Array\f[R] containing the PCM data associated
with the channel, defined by the \f[CR]channel\f[R] parameter (with
\f[CR]0\f[R] representing the first channel).
.TP
\f[B]AudioBuffer.copyFromChannel()\f[R]
Copies the samples from the specified channel of the
\f[CR]AudioBuffer\f[R] to the \f[CR]destination\f[R] array.
.TP
\f[B]AudioBuffer.copyToChannel()\f[R]
Copies the samples to the specified channel of the
\f[CR]AudioBuffer\f[R], from the \f[CR]source\f[R] array.
.SH EXAMPLE
The following simple example shows how to create an
\f[CR]AudioBuffer\f[R] and fill it with random white noise.
You can find the full source code at our \c
.UR https://github.com/mdn/webaudio-examples
webaudio\-examples
.UE \c
\ repository; a \c
.UR https://mdn.github.io/webaudio-examples/audio-buffer/
running live
.UE \c
\ version is also available.
.IP
.EX
const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

// Create an empty three\-second stereo buffer at the sample rate of the AudioContext
const myArrayBuffer = audioCtx.createBuffer(
  2,
  audioCtx.sampleRate * 3,
  audioCtx.sampleRate,
);

// Fill the buffer with white noise;
// just random values between \-1.0 and 1.0
for (let channel = 0; channel < myArrayBuffer.numberOfChannels; channel++) {
  // This gives us the actual array that contains the data
  const nowBuffering = myArrayBuffer.getChannelData(channel);
  for (let i = 0; i < myArrayBuffer.length; i++) {
    // Math.random() is in [0; 1.0]
    // audio needs to be in [\-1.0; 1.0]
    nowBuffering[i] = Math.random() * 2 \- 1;
  }
}

// Get an AudioBufferSourceNode.
// This is the AudioNode to use when we want to play an AudioBuffer
const source = audioCtx.createBufferSource();

// set the buffer in the AudioBufferSourceNode
source.buffer = myArrayBuffer;

// connect the AudioBufferSourceNode to the
// destination so we can hear the sound
source.connect(audioCtx.destination);

// start the source playing
source.start();
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API
