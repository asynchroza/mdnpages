.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "SpeechSynthesis" "JS" "March 3, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
SpeechSynthesis \- SpeechSynthesis
.SH SYNOPSIS
The \f[B]\f[CB]SpeechSynthesis\f[B]\f[R] interface of the Web Speech API
is the controller interface for the speech service; this can be used to
retrieve information about the synthesis voices available on the device,
start and pause speech, and other commands besides.
.SH INSTANCE PROPERTIES
\f[I]\f[CI]SpeechSynthesis\f[I] also inherits properties from its parent
interface, \f[CI]EventTarget\f[I].\f[R]
.TP
\f[B]SpeechSynthesis.paused\f[R] \f[I](read\-only)\f[R]
A boolean value that returns \f[CR]true\f[R] if the
\f[CR]SpeechSynthesis\f[R] object is in a paused state.
.TP
\f[B]SpeechSynthesis.pending\f[R] \f[I](read\-only)\f[R]
A boolean value that returns \f[CR]true\f[R] if the utterance queue
contains as\-yet\-unspoken utterances.
.TP
\f[B]SpeechSynthesis.speaking\f[R] \f[I](read\-only)\f[R]
A boolean value that returns \f[CR]true\f[R] if an utterance is
currently in the process of being spoken \[em] even if
\f[CR]SpeechSynthesis\f[R] is in a paused state.
.SH INSTANCE METHODS
\f[I]\f[CI]SpeechSynthesis\f[I] also inherits methods from its parent
interface, \f[CI]EventTarget\f[I].\f[R]
.TP
\f[B]SpeechSynthesis.cancel()\f[R]
Removes all utterances from the utterance queue.
.TP
\f[B]SpeechSynthesis.getVoices()\f[R]
Returns a list of \f[CR]SpeechSynthesisVoice\f[R] objects representing
all the available voices on the current device.
.TP
\f[B]SpeechSynthesis.pause()\f[R]
Puts the \f[CR]SpeechSynthesis\f[R] object into a paused state.
.TP
\f[B]SpeechSynthesis.resume()\f[R]
Puts the \f[CR]SpeechSynthesis\f[R] object into a non\-paused state:
resumes it if it was already paused.
.TP
\f[B]SpeechSynthesis.speak()\f[R]
Adds an \f[CR]utterance\f[R] to the utterance queue; it will be spoken
when any other utterances queued before it have been spoken.
.SH EVENTS
Listen to this event using \f[CR]addEventListener()\f[R] or by assigning
an event listener to the \f[CR]oneventname\f[R] property of this
interface.
.TP
\f[B]voiceschanged\f[R]
Fired when the list of \f[CR]SpeechSynthesisVoice\f[R] objects that
would be returned by the \f[CR]SpeechSynthesis.getVoices()\f[R] method
has changed.
Also available via the \f[CR]onvoiceschanged\f[R] property.
.SH EXAMPLES
First, a simple example:
.IP
.EX
let utterance = new SpeechSynthesisUtterance(\[dq]Hello world!\[dq]);
speechSynthesis.speak(utterance);
.EE
.PP
Now we\[cq]ll look at a more fully\-fledged example.
In our \c
.UR
https://github.com/mdn/dom-examples/tree/main/web-speech-api/speak-easy-synthesis
Speech synthesizer demo
.UE \c
, we first grab a reference to the SpeechSynthesis controller using
\f[CR]window.speechSynthesis\f[R].
After defining some necessary variables, we retrieve a list of the
voices available using \f[CR]SpeechSynthesis.getVoices()\f[R] and
populate a select menu with them so the user can choose what voice they
want.
.PP
Inside the \f[CR]inputForm.onsubmit\f[R] handler, we stop the form
submitting with preventDefault(), create a new
\f[CR]SpeechSynthesisUtterance\f[R] instance containing the text from
the text \f[CR]<input>\f[R], set the utterance\[cq]s voice to the voice
selected in the \f[CR]<select>\f[R] element, and start the utterance
speaking via the \f[CR]SpeechSynthesis.speak()\f[R] method.
.IP
.EX
const synth = window.speechSynthesis;

const inputForm = document.querySelector(\[dq]form\[dq]);
const inputTxt = document.querySelector(\[dq].txt\[dq]);
const voiceSelect = document.querySelector(\[dq]select\[dq]);
const pitch = document.querySelector(\[dq]#pitch\[dq]);
const pitchValue = document.querySelector(\[dq].pitch\-value\[dq]);
const rate = document.querySelector(\[dq]#rate\[dq]);
const rateValue = document.querySelector(\[dq].rate\-value\[dq]);

let voices = [];

function populateVoiceList() {
  voices = synth.getVoices();

  for (let i = 0; i < voices.length; i++) {
    const option = document.createElement(\[dq]option\[dq]);
    option.textContent = \[ga]${voices[i].name} (${voices[i].lang})\[ga];

    if (voices[i].default) {
      option.textContent += \[dq] \[em] DEFAULT\[dq];
    }

    option.setAttribute(\[dq]data\-lang\[dq], voices[i].lang);
    option.setAttribute(\[dq]data\-name\[dq], voices[i].name);
    voiceSelect.appendChild(option);
  }
}

populateVoiceList();
if (speechSynthesis.onvoiceschanged !== undefined) {
  speechSynthesis.onvoiceschanged = populateVoiceList;
}

inputForm.onsubmit = (event) => {
  event.preventDefault();

  const utterThis = new SpeechSynthesisUtterance(inputTxt.value);
  const selectedOption =
    voiceSelect.selectedOptions[0].getAttribute(\[dq]data\-name\[dq]);
  for (let i = 0; i < voices.length; i++) {
    if (voices[i].name === selectedOption) {
      utterThis.voice = voices[i];
    }
  }
  utterThis.pitch = pitch.value;
  utterThis.rate = rate.value;
  synth.speak(utterThis);

  inputTxt.blur();
};
.EE
.SH SEE ALSO
.IP \[bu] 2
Web Speech API
