.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "RTCEncodedAudioFrame.data" "JS" "September 8, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
RTCEncodedAudioFrame.data \- RTCEncodedAudioFrame: data property
.SH SYNOPSIS
The \f[B]\f[CB]data\f[B]\f[R] property of the
\f[CR]RTCEncodedAudioFrame\f[R] interface returns a buffer containing
the data for an encoded frame.
.SH VALUE
An \f[CR]ArrayBuffer\f[R].
.SH EXAMPLES
This example WebRTC encoded transform shows how you might get the frame
data in a \f[CR]TransformStream\f[R] \f[CR]transform()\f[R] function
modify the bits.
.PP
The \f[CR]transform()\f[R] function constructs a \f[CR]DataView\f[R] on
the buffer in the frame \f[CR]data\f[R] property, and also creates a
view on a new \f[CR]ArrayBuffer\f[R].
It then writes the negated bytes in the original data to the new buffer,
assigns the buffer to the encoded frame \f[CR]data\f[R] property, and
enqueues the modified frame on the stream.
.IP
.EX
addEventListener(\[dq]rtctransform\[dq], (event) => {
  const transform = new TransformStream({
    async transform(encodedFrame, controller) {
      // Reconstruct the original frame.
      const view = new DataView(encodedFrame.data);

      // Construct a new buffer
      const newData = new ArrayBuffer(encodedFrame.data.byteLength);
      const newView = new DataView(newData);

      // Negate all bits in the incoming frame
      for (let i = 0; i < encodedFrame.data.byteLength; ++i) {
        newView.setInt8(i, \[ti]view.getInt8(i));
      }

      encodedFrame.data = newData;
      controller.enqueue(encodedFrame);
    },
  });
  event.transformer.readable
    .pipeThrough(transform)
    .pipeTo(event.transformer.writable);
});
.EE
.PP
Note that the surrounding code shown here is described in Using WebRTC
Encoded Transforms.
.SH SEE ALSO
.IP \[bu] 2
Using WebRTC Encoded Transforms
