.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "SpeechSynthesisVoice" "JS" "July 7, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
SpeechSynthesisVoice \- SpeechSynthesisVoice
.SH SYNOPSIS
The \f[B]\f[CB]SpeechSynthesisVoice\f[B]\f[R] interface of the Web
Speech API represents a voice that the system supports.
Every \f[CR]SpeechSynthesisVoice\f[R] has its own relative speech
service including information about language, name and URI.
.SH INSTANCE PROPERTIES
.TP
\f[B]SpeechSynthesisVoice.default\f[R] \f[I](read\-only)\f[R]
A boolean value indicating whether the voice is the default voice for
the current app language (\f[CR]true\f[R]), or not (\f[CR]false\f[R].)
.TP
\f[B]SpeechSynthesisVoice.lang\f[R] \f[I](read\-only)\f[R]
Returns a BCP 47 language tag indicating the language of the voice.
.TP
\f[B]SpeechSynthesisVoice.localService\f[R] \f[I](read\-only)\f[R]
A boolean value indicating whether the voice is supplied by a local
speech synthesizer service (\f[CR]true\f[R]), or a remote speech
synthesizer service (\f[CR]false\f[R].)
.TP
\f[B]SpeechSynthesisVoice.name\f[R] \f[I](read\-only)\f[R]
Returns a human\-readable name that represents the voice.
.TP
\f[B]SpeechSynthesisVoice.voiceURI\f[R] \f[I](read\-only)\f[R]
Returns the type of URI and location of the speech synthesis service for
this voice.
.SH EXAMPLES
The following snippet is excerpted from our \c
.UR
https://github.com/mdn/dom-examples/blob/main/web-speech-api/speak-easy-synthesis/script.js
Speech synthesizer demo
.UE \c
\&.
.IP
.EX
const synth = window.speechSynthesis;
function populateVoiceList() {
  voices = synth.getVoices();

  for (let i = 0; i < voices.length; i++) {
    const option = document.createElement(\[dq]option\[dq]);
    option.textContent = \[ga]${voices[i].name} (${voices[i].lang})\[ga];

    if (voices[i].default) {
      option.textContent += \[dq] \[em] DEFAULT\[dq];
    }

    option.setAttribute(\[dq]data\-lang\[dq], voices[i].lang);
    option.setAttribute(\[dq]data\-name\[dq], voices[i].name);
    voiceSelect.appendChild(option);
  }
}

populateVoiceList();
if (speechSynthesis.onvoiceschanged !== undefined) {
  speechSynthesis.onvoiceschanged = populateVoiceList;
}

inputForm.onsubmit = (event) => {
  event.preventDefault();

  const utterThis = new SpeechSynthesisUtterance(inputTxt.value);
  const selectedOption =
    voiceSelect.selectedOptions[0].getAttribute(\[dq]data\-name\[dq]);
  for (let i = 0; i < voices.length; i++) {
    if (voices[i].name === selectedOption) {
      utterThis.voice = voices[i];
    }
  }
  utterThis.pitch = pitch.value;
  utterThis.rate = rate.value;
  synth.speak(utterThis);

  utterThis.onpause = (event) => {
    const char = event.utterance.text.charAt(event.charIndex);
    console.log(
      \[ga]Speech paused at character ${event.charIndex} of \[dq]${event.utterance.text}\[dq], which is \[dq]${char}\[dq].\[ga],
    );
  };

  inputTxt.blur();
};
.EE
.SH SEE ALSO
.IP \[bu] 2
Web Speech API
