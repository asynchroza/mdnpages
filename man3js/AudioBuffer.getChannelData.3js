.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "AudioBuffer.getChannelData" "JS" "April 6, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioBuffer.getChannelData \- AudioBuffer: getChannelData() method
.SH SYNOPSIS
The \f[B]\f[CB]getChannelData()\f[B]\f[R] method of the
\f[CR]AudioBuffer\f[R] Interface returns a \f[CR]Float32Array\f[R]
containing the PCM data associated with the channel, defined by the
channel parameter (with 0 representing the first channel).
.SH SYNTAX
.IP
.EX
getChannelData(channel)
.EE
.SS Parameters
.TP
\f[B]channel\f[R]
The channel property is an index representing the particular channel to
get data for.
An index value of 0 represents the first channel.
If the \f[CR]channel\f[R] index value is greater than of equal to
\f[CR]AudioBuffer.numberOfChannels\f[R], an \f[CR]INDEX_SIZE_ERR\f[R]
exception will be thrown.
.SS Return value
A \f[CR]Float32Array\f[R].
.SH EXAMPLES
In the following example we create a two second buffer, fill it with
white noise, and then play it via an \f[CR]AudioBufferSourceNode\f[R].
The comments should clearly explain what is going on.
You can also \c
.UR https://mdn.github.io/webaudio-examples/audio-buffer/
run the code live
.UE \c
, or \c
.UR https://github.com/mdn/webaudio-examples
view the source
.UE \c
\&.
.IP
.EX
const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
const button = document.querySelector(\[dq]button\[dq]);
const pre = document.querySelector(\[dq]pre\[dq]);
const myScript = document.querySelector(\[dq]script\[dq]);

pre.innerHTML = myScript.innerHTML;

// Stereo
const channels = 2;
// Create an empty two second stereo buffer at the
// sample rate of the AudioContext
const frameCount = audioCtx.sampleRate * 2.0;

const myArrayBuffer = audioCtx.createBuffer(2, frameCount, audioCtx.sampleRate);

button.onclick = () => {
  // Fill the buffer with white noise;
  //just random values between \-1.0 and 1.0
  for (let channel = 0; channel < channels; channel++) {
    // This gives us the actual ArrayBuffer that contains the data
    const nowBuffering = myArrayBuffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      // Math.random() is in [0; 1.0]
      // audio needs to be in [\-1.0; 1.0]
      nowBuffering[i] = Math.random() * 2 \- 1;
    }
  }

  // Get an AudioBufferSourceNode.
  // This is the AudioNode to use when we want to play an AudioBuffer
  const source = audioCtx.createBufferSource();
  // set the buffer in the AudioBufferSourceNode
  source.buffer = myArrayBuffer;
  // connect the AudioBufferSourceNode to the
  // destination so we can hear the sound
  source.connect(audioCtx.destination);
  // start the source playing
  source.start();
};
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API
