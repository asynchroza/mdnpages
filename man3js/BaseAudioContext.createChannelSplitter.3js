.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "BaseAudioContext.createChannelSplitter" "JS" "April 6, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
BaseAudioContext.createChannelSplitter \- BaseAudioContext:
createChannelSplitter() method
.SH SYNOPSIS
The \f[CR]createChannelSplitter()\f[R] method of the
\f[CR]BaseAudioContext\f[R] Interface is used to create a
\f[CR]ChannelSplitterNode\f[R], which is used to access the individual
channels of an audio stream and process them separately.
.RS
.PP
\f[B]Note:\f[R] The \f[CR]ChannelSplitterNode()\f[R] constructor is the
recommended way to create a \f[CR]ChannelSplitterNode\f[R]; see Creating
an AudioNode.
.RE
.SH SYNTAX
.IP
.EX
createChannelSplitter(numberOfOutputs)
.EE
.SS Parameters
.TP
\f[B]numberOfOutputs\f[R]
The number of channels in the input audio stream that you want to output
separately; the default is 6 if this parameter is not specified.
.SS Return value
A \f[CR]ChannelSplitterNode\f[R].
.SH EXAMPLES
The following simple example shows how you could separate a stereo track
(say, a piece of music), and process the left and right channel
differently.
To use them, you need to use the second and third parameters of the
\f[CR]AudioNode.connect(AudioNode)\f[R] method, which allow you to
specify the index of the channel to connect from and the index of the
channel to connect to.
.IP
.EX
const ac = new AudioContext();
ac.decodeAudioData(someStereoBuffer, (data) => {
  const source = ac.createBufferSource();
  source.buffer = data;
  const splitter = ac.createChannelSplitter(2);
  source.connect(splitter);
  const merger = ac.createChannelMerger(2);

  // Reduce the volume of the left channel only
  const gainNode = ac.createGain();
  gainNode.gain.setValueAtTime(0.5, ac.currentTime);
  splitter.connect(gainNode, 0);

  // Connect the splitter back to the second input of the merger: we
  // effectively swap the channels, here, reversing the stereo image.
  gainNode.connect(merger, 0, 1);
  splitter.connect(merger, 1, 0);

  const dest = ac.createMediaStreamDestination();

  // Because we have used a ChannelMergerNode, we now have a stereo
  // MediaStream we can use to pipe the Web Audio graph to WebRTC,
  // MediaRecorder, etc.
  merger.connect(dest);
});
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API
