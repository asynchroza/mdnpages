.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "AudioBufferSourceNode.loopStart" "JS" "November 21, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioBufferSourceNode.loopStart \- AudioBufferSourceNode: loopStart
property
.SH SYNOPSIS
The \f[B]\f[CB]loopStart\f[B]\f[R] property of the
\f[CR]AudioBufferSourceNode\f[R] interface is a floating\-point value
indicating, in seconds, where in the \f[CR]AudioBuffer\f[R] the restart
of the play must happen.
.PP
The \f[CR]loopStart\f[R] property\[cq]s default value is \f[CR]0\f[R].
.SH VALUE
A floating\-point number indicating the offset, in seconds, into the
audio buffer at which each loop should begin during playback.
This value is only used when the \f[CR]loop\f[R] parameter is
\f[CR]true\f[R].
.SH EXAMPLES
.SS Setting \f[CR]loopStart\f[R]
In this example, when the user presses \[lq]Play\[rq], we load an audio
track, decode it, and put it into an \f[CR]AudioBufferSourceNode\f[R].
.PP
The example then sets the \f[CR]loop\f[R] property to \f[CR]true\f[R],
so the track loops, and plays the track.
.PP
The user can set the \f[CR]loopStart\f[R] and and \f[CR]loopEnd\f[R]
properties using range controls.
.RS
.PP
\f[B]Note:\f[R] You can \c
.UR
https://mdn.github.io/webaudio-examples/audio-buffer-source-node/loop/
run the full example live
.UE \c
\ (or \c
.UR
https://github.com/mdn/webaudio-examples/tree/main/audio-buffer-source-node/loop
view the source
.UE \c
\&.)
.RE
.IP
.EX
let audioCtx;
let buffer;
let source;

const play = document.getElementById(\[dq]play\[dq]);
const stop = document.getElementById(\[dq]stop\[dq]);

const loopstartControl = document.getElementById(\[dq]loopstart\-control\[dq]);
const loopstartValue = document.getElementById(\[dq]loopstart\-value\[dq]);

const loopendControl = document.getElementById(\[dq]loopend\-control\[dq]);
const loopendValue = document.getElementById(\[dq]loopend\-value\[dq]);

async function loadAudio() {
  try {
    // Load an audio file
    const response = await fetch(\[dq]rnb\-lofi\-melody\-loop.wav\[dq]);
    // Decode it
    buffer = await audioCtx.decodeAudioData(await response.arrayBuffer());
    const max = Math.floor(buffer.duration);
    loopstartControl.setAttribute(\[dq]max\[dq], max);
    loopendControl.setAttribute(\[dq]max\[dq], max);
  } catch (err) {
    console.error(\[ga]Unable to fetch the audio file. Error: ${err.message}\[ga]);
  }
}

play.addEventListener(\[dq]click\[dq], async () => {
  if (!audioCtx) {
    audioCtx = new AudioContext();
    await loadAudio();
  }
  source = audioCtx.createBufferSource();
  source.buffer = buffer;
  source.connect(audioCtx.destination);
  source.loop = true;
  source.loopStart = loopstartControl.value;
  source.loopEnd = loopendControl.value;
  source.start();
  play.disabled = true;
  stop.disabled = false;
  loopstartControl.disabled = false;
  loopendControl.disabled = false;
});

stop.addEventListener(\[dq]click\[dq], () => {
  source.stop();
  play.disabled = false;
  stop.disabled = true;
  loopstartControl.disabled = true;
  loopendControl.disabled = true;
});

loopstartControl.addEventListener(\[dq]input\[dq], () => {
  source.loopStart = loopstartControl.value;
  loopstartValue.textContent = loopstartControl.value;
});

loopendControl.addEventListener(\[dq]input\[dq], () => {
  source.loopEnd = loopendControl.value;
  loopendValue.textContent = loopendControl.value;
});
.EE
.SH SEE ALSO
.IP \[bu] 2
Web Audio API
.IP \[bu] 2
Using the Web Audio API
