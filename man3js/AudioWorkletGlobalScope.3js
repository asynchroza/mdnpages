.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "AudioWorkletGlobalScope" "JS" "November 29, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioWorkletGlobalScope \- AudioWorkletGlobalScope
.SH SYNOPSIS
The \f[B]\f[CB]AudioWorkletGlobalScope\f[B]\f[R] interface of the Web
Audio API represents a global execution context for user\-supplied code,
which defines custom \f[CR]AudioWorkletProcessor\f[R]\-derived classes.
.PP
Each \f[CR]BaseAudioContext\f[R] has a single \f[CR]AudioWorklet\f[R]
available under the \f[CR]audioWorklet\f[R] property, which runs its
code in a single \f[CR]AudioWorkletGlobalScope\f[R].
.PP
As the global execution context is shared across the current
\f[CR]BaseAudioContext\f[R], it\[cq]s possible to define any other
variables and perform any actions allowed in worklets \[em] apart from
defining \f[CR]AudioWorkletProcessor\f[R] derived classes.
.SH INSTANCE PROPERTIES
\f[I]This interface also inherits properties defined on its parent
interface, \f[CI]WorkletGlobalScope\f[I].\f[R]
.TP
\f[B]currentFrame\f[R] \f[I](read\-only)\f[R]
Returns an integer that represents the ever\-increasing current
sample\-frame of the audio block being processed.
It is incremented by 128 (the size of a render quantum) after the
processing of each audio block.
.TP
\f[B]currentTime\f[R] \f[I](read\-only)\f[R]
Returns a double that represents the ever\-increasing context time of
the audio block being processed.
It is equal to the \f[CR]currentTime\f[R] property of the
\f[CR]BaseAudioContext\f[R] the worklet belongs to.
.TP
\f[B]sampleRate\f[R] \f[I](read\-only)\f[R]
Returns a float that represents the sample rate of the associated
\f[CR]BaseAudioContext\f[R].
.SH INSTANCE METHODS
\f[I]This interface also inherits methods defined on its parent
interface, \f[CI]WorkletGlobalScope\f[I].\f[R]
.TP
\f[B]registerProcessor()\f[R]
Registers a class derived from the \f[CR]AudioWorkletProcessor\f[R]
interface.
The class can then be used by creating an \f[CR]AudioWorkletNode\f[R],
providing its registered name.
.SH EXAMPLES
In this example we output all global properties into the console in the
constructor of a custom \f[CR]AudioWorkletProcessor\f[R].
.PP
First we need to define the processor, and register it.
Note that this should be done in a separate file.
.IP
.EX
// AudioWorkletProcessor defined in : test\-processor.js
class TestProcessor extends AudioWorkletProcessor {
  constructor() {
    super();

    // Logs the current sample\-frame and time at the moment of instantiation.
    // They are accessible from the AudioWorkletGlobalScope.
    console.log(currentFrame);
    console.log(currentTime);
  }

  // The process method is required \- output silence,
  // which the outputs are already filled with.
  process(inputs, outputs, parameters) {
    return true;
  }
}

// Logs the sample rate, that is not going to change ever,
// because it\[aq]s a read\-only property of a BaseAudioContext
// and is set only during its instantiation.
console.log(sampleRate);

// You can declare any variables and use them in your processors
// for example it may be an ArrayBuffer with a wavetable
const usefulVariable = 42;
console.log(usefulVariable);

registerProcessor(\[dq]test\-processor\[dq], TestProcessor);
.EE
.PP
Next, in our main scripts file we\[cq]ll load the processor, create an
instance of \f[CR]AudioWorkletNode\f[R] \[em] passing the name of the
processor to it \[em] and connect the node to an audio graph.
We should see the output of \f[CR]console.log()\f[R] calls in the
console:
.IP
.EX
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule(\[dq]test\-processor.js\[dq]);
const testNode = new AudioWorkletNode(audioContext, \[dq]test\-processor\[dq]);
testNode.connect(audioContext.destination);
.EE
.SH SEE ALSO
.IP \[bu] 2
Web Audio API
.IP \[bu] 2
Using the Web Audio API
.IP \[bu] 2
Using AudioWorklet
